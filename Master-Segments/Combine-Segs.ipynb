{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import arcpy\n",
    "from arcgis.gis import *\n",
    "import datetime\n",
    "gis = GIS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Merge Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this script, please visually inspect if all the shapefiles meet the following criteria\n",
    "\n",
    " 1. Each shapefile only includes those segments whose centroid falls within their corresponding subarea.\n",
    " 2. Each shapefile includes a SUBAREAID field that is correct.\n",
    " \n",
    "If any of the shapefiles do not meet the criteria, you must fix that shapefile before moving forward. Below is an example of how Iron county segment shapefile was fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, October 23, 2023 3:33:29 PM\",\"Succeeded at Monday, October 23, 2023 3:33:29 PM (Elapsed Time: 0.04 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '../data/5_IronCo - v1.0 - 2023-09-13_DRAFT/Segments_IR_20230912b/Segments_IR_20230912c.shp'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The IronCo Segment file does not include a SUBAREAID column, so we add one: \n",
    "input_shapefile = r'../data/5_IronCo - v1.0 - 2023-09-13_DRAFT/Segments_IR_20230912b/Segments_IR_20230912b.shp'\n",
    "output_shapefile = input_shapefile.replace('b.shp', 'c.shp')\n",
    "\n",
    "arcpy.management.CopyFeatures(input_shapefile, output_shapefile)\n",
    "arcpy.management.AddField(output_shapefile, \"SUBAREAID\", \"SHORT\")\n",
    "arcpy.management.CalculateField(output_shapefile, \"SUBAREAID\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, October 23, 2023 3:34:21 PM\",\"Succeeded at Monday, October 23, 2023 3:34:21 PM (Elapsed Time: 0.06 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '../data/2_Cache/Segments_CA_20231023/Segments_CA_20231023b.shp'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The CacheCo Segment file does not include a SUBAREAID column, so we add one:\n",
    "input_shapefile = r'../data/2_Cache/Segments_CA_20231023/Segments_CA_20231023a.shp'\n",
    "output_shapefile = input_shapefile.replace('a.shp', 'b.shp')\n",
    "\n",
    "arcpy.management.CopyFeatures(input_shapefile, output_shapefile)\n",
    "arcpy.management.AddField(output_shapefile, \"SUBAREAID\", \"SHORT\")\n",
    "arcpy.management.CalculateField(output_shapefile, \"SUBAREAID\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the workspace environment to the folder where the output shapefile will be stored\n",
    "arcpy.env.workspace = 'D:/GitHub/UDOT-Master-Segments/outputs/'\n",
    "\n",
    "# List of input shapefile paths\n",
    "shpPaths = [\n",
    "    '../data/0_USTM_v3.0 - 2023-08-17_DRAFT/Segments_UD_20230729/Segments_UD_20220729b.shp',\n",
    "    '../data/1_WF/Segments_WF_20230919/Segments_WF_20230919.shp',\n",
    "    '../data/2_Cache/Segments_CA_20231023/Segments_CA_20231023b.shp',\n",
    "    '../data/3_Dixie/Segments_DX_20220915b/Segments_DX_20220915b.shp',\n",
    "    '../data/4_SuWsv2_2023-09-13_DRAFT/Segments_SW_20230913/Segments_SW_20230913.shp',\n",
    "    '../data/5_IronCo - v1.0 - 2023-09-13_DRAFT/Segments_IR_20230912b/Segments_IR_20230912c.shp'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all segment shapefiles have the correct segments and their subareaid is correct, we can move forward by merging them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, October 23, 2023 3:35:43 PM\",\"Succeeded at Monday, October 23, 2023 3:35:45 PM (Elapsed Time: 1.97 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '..\\\\intermediate\\\\1_Merged_Segments.shp'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output merged shapefile path\n",
    "inputShp = '../intermediate/1_Merged_Segments.shp'\n",
    "\n",
    "# Use arcpy.management.Merge with FieldMappings to merge the shapefiles\n",
    "fieldMappings = arcpy.FieldMappings()\n",
    "fieldMappings.mergeRule = 'Join'\n",
    "arcpy.management.Merge(shpPaths, inputShp, fieldMappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Post Merge Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before moving on, we must check the CRS and for duplicate SEGIDS of this new merged file. If the crs is not correct, or if duplicate SEGIDs exist, we must fix those before performing the other steps. This fixing should be done to the individual subarea segment shapefiles instead of as a whole here. \n",
    "\n",
    "(Technically these checks should be performed individually for each segment shapefile before this script, but we double check here anyway)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Check CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate System: NAD_1983_UTM_Zone_12N\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Use arcpy.Describe to get information about the shapefile\n",
    "    desc = arcpy.Describe(joinShp)\n",
    "    \n",
    "    # Check if the shapefile has a spatial reference (projection)\n",
    "    if desc.spatialReference is not None:\n",
    "        # Get the name of the coordinate system\n",
    "        coordinate_system_name = desc.spatialReference.name\n",
    "        \n",
    "        # Print the coordinate system information\n",
    "        print(f\"Coordinate System: {coordinate_system_name}\")\n",
    "    else:\n",
    "        print(\"The shapefile does not have a defined coordinate system.\")\n",
    "except arcpy.ExecuteError:\n",
    "    print(arcpy.GetMessages(2))\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate SEGIDs found in Merged_Segments.shp.\n"
     ]
    }
   ],
   "source": [
    "# Create a set to store unique SEGID values\n",
    "uniqueSegIDs = set()\n",
    "\n",
    "# Create a list to store duplicate SEGID values\n",
    "duplicateSegIDs = []\n",
    "\n",
    "# Use a SearchCursor to iterate through the SEGID field\n",
    "with arcpy.da.SearchCursor(joinShp, ['SEGID']) as cursor:\n",
    "    for row in cursor:\n",
    "        segid = row[0]\n",
    "        if segid in uniqueSegIDs:\n",
    "            duplicateSegIDs.append(segid)\n",
    "        else:\n",
    "            uniqueSegIDs.add(segid)\n",
    "\n",
    "# Check if there are any duplicate SEGIDs\n",
    "if len(duplicateSegIDs) > 0:\n",
    "    print(\"Duplicate SEGIDs found in Merged_Segments.shp:\")\n",
    "    for segid in duplicateSegIDs:\n",
    "        print(segid)\n",
    "else:\n",
    "    print(\"No duplicate SEGIDs found in Merged_Segments.shp.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Merge Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will clean up the fields of the merged segment file. This will include selecting the necessary fields as well as recalculating certain fields to ensure they are up to date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Necessary Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify the input shapefile path\n",
    "# ADD AADT_2019 TO FINAL FILE\n",
    "fields_to_keep = ['FID', 'Shape', 'SEGID', 'PLANAREA', 'SUBAREAID', 'BMP','EMP', 'AADT2019']# 'DISTANCE', 'CO_FIPS', 'FAC_WDAVG', 'FAC_SPR', 'FAC_SUM', 'FAC_FAL', 'FAC_WIN']\n",
    "inputShp = r'../intermediate/1_Merged_Segments.shp'\n",
    "outputShp = r'../intermediate/2_Merged_Segments.shp'\n",
    "\n",
    "try:  \n",
    "    # Copy the source shapefile to the destination\n",
    "    arcpy.CopyFeatures_management(inputShp, outputShp)\n",
    "    \n",
    "    # Delete unwanted fields from the copied shapefile\n",
    "    fields_to_delete = [field.name for field in arcpy.ListFields(outputShp) if field.name not in fields_to_keep]\n",
    "    arcpy.management.DeleteField(outputShp, fields_to_delete)\n",
    "\n",
    "    print(\"Columns deleted successfully.\")\n",
    "except arcpy.ExecuteError:\n",
    "    print(arcpy.GetMessages(2))\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the DISTANCE Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the DISTANCE Field already exists in the dataset, we need to recalculate it to ensure all SEGIDs in the state have a correct value. The following code does just that by adding the DISTANCE field to the shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTANCE field calculated successfully.\n",
      "    DISTANCE\n",
      "0   0.666642\n",
      "1  15.369870\n",
      "2  30.002021\n",
      "3  14.194335\n",
      "4  17.323272\n"
     ]
    }
   ],
   "source": [
    "# Specify the input shapefile path and other variables\n",
    "inputShp = r'../intermediate/2_Merged_Segments.shp'\n",
    "outputShp = r'../intermediate/3_Merged_Segments.shp'\n",
    "distanceField = \"DISTANCE\"\n",
    "meters_to_miles = 0.000621371192\n",
    "\n",
    "try:\n",
    "    # Copy the source shapefile to the destination\n",
    "    arcpy.CopyFeatures_management(inputShp, outputShp)\n",
    "    \n",
    "    # Create an empty DISTANCE field\n",
    "    arcpy.management.AddField(outputShp, \"DISTANCE\", \"DOUBLE\")\n",
    "    \n",
    "    # Create an update cursor to calculate the DISTANCE2 field\n",
    "    with arcpy.da.UpdateCursor(outputShp, ['SHAPE@', distanceField]) as cursor:\n",
    "        for row in cursor:\n",
    "            # Get the segment's geometry and calculate its length in meters\n",
    "            segment_geometry = row[0]\n",
    "            segment_length = segment_geometry.length * meters_to_miles\n",
    "\n",
    "            # Update the DISTANCE2 field with the calculated length in meters\n",
    "            row[1] = segment_length\n",
    "            cursor.updateRow(row)\n",
    "    \n",
    "    # print statements for checking\n",
    "    print(f\"{distanceField} field calculated successfully.\")\n",
    "    df = pd.DataFrame.spatial.from_featureclass(outputShp)\n",
    "    print(df[['DISTANCE']].head(5))\n",
    "    \n",
    "except arcpy.ExecuteError:\n",
    "    print(arcpy.GetMessages(2))\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the CO_FIPS Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the DISTANCE FIELD, although CO_FIPS already exists, we need to calculate it again to ensure it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in county boundaries from UGRC Website as well as intermediate shapefiles\n",
    "countyShp = r'../data/Utah_County_Boundaries/Counties.shp'\n",
    "inputShp = r'../intermediate/3_Merged_Segments.shp'\n",
    "outputShp = r'../intermediate/4_Merged_Segments.shp'\n",
    "int_centroids = r'../intermediate/Centroids.shp'\n",
    "int_cofip_centroids = r'../intermediate/Centroids_with_CO_FIPS.shp'\n",
    "\n",
    "# Specify the input shapefile path\n",
    "co_fields_to_keep = ['FID', 'Shape', 'SEGID', 'PLANAREA', 'DISTANCE','SUBAREAID', 'BMP','EMP', 'AADT2019', 'FIPS']\n",
    "\n",
    "try:  \n",
    "    # Perform FeatureToPoint to create centroids\n",
    "    arcpy.management.FeatureToPoint(inputShp, int_centroids, \"INSIDE\")\n",
    "    \n",
    "    # Perform spatial join with centroids and subarea shapefile\n",
    "    arcpy.analysis.SpatialJoin(target_features=int_centroids, join_features=countyShp, out_feature_class=int_cofip_centroids, join_type=\"KEEP_COMMON\", match_option=\"WITHIN\")\n",
    "   \n",
    "    # Perform spatial join with clipped centroids and segments\n",
    "    arcpy.analysis.SpatialJoin(target_features=inputShp, join_features=int_cofip_centroids, out_feature_class=outputShp, join_type=\"KEEP_COMMON\", match_option=\"INTERSECT\")\n",
    "    \n",
    "    # Delete unwanted fields from the copied shapefile\n",
    "    co_fields_to_delete = [field.name for field in arcpy.ListFields(outputShp) if field.name not in co_fields_to_keep]\n",
    "    if co_fields_to_delete:\n",
    "        arcpy.management.DeleteField(outputShp, co_fields_to_delete)\n",
    "\n",
    "    # Delete the intermediate files\n",
    "    arcpy.management.Delete(int_centroids)\n",
    "    arcpy.management.Delete(int_cofip_centroids)\n",
    "    \n",
    "except arcpy.ExecuteError:\n",
    "    print(arcpy.GetMessages(2))\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Overrides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few segments that need some manual overridding. \n",
    " - DIXIE_5134 should be SUBAREAID 3 and CO_FIPS should be 53\n",
    " - 1822_000.0 should be SUBAREAID 1 and CO_FIPS should be 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, October 23, 2023 3:36:33 PM\",\"Succeeded at Monday, October 23, 2023 3:36:33 PM (Elapsed Time: 0.01 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shapefiles\n",
    "input_shp_3 = r'../intermediate/3_Merged_Segments.shp'  # Source shapefile with the specific segment\n",
    "input_shp_4 = r'../intermediate/4_Merged_Segments.shp'  # Target shapefile to join to\n",
    "output_shp = r'../intermediate/5_Merged_Segments.shp'\n",
    "output_shp_dixie = r'../intermediate/Dixie_Segment.shp'\n",
    "\n",
    "# Create a new shapefile by copying the target shapefile\n",
    "arcpy.CopyFeatures_management(input_shp_4, output_shp)\n",
    "\n",
    "# Create a feature layer and apply a SQL query to select the desired row\n",
    "arcpy.management.MakeFeatureLayer(input_shp_3, \"Temp_Layer\")\n",
    "arcpy.management.SelectLayerByAttribute(\"Temp_Layer\", \"NEW_SELECTION\", \"SEGID = 'Dixie_5134'\")\n",
    "\n",
    "# Copy the selected features to a new shapefile\n",
    "arcpy.management.CopyFeatures(\"Temp_Layer\", output_shp_dixie)\n",
    "arcpy.management.Delete(\"Temp_Layer\")\n",
    "\n",
    "# Manually Calculate the fields for Dixie_5134\n",
    "arcpy.management.AddField(output_shp_dixie, \"FIPS\", \"SHORT\")\n",
    "arcpy.management.CalculateField(output_shp_dixie, \"SUBAREAID\", 3)\n",
    "arcpy.management.CalculateField(output_shp_dixie, \"FIPS\", 53)\n",
    "\n",
    "# Use the Append tool to merge the Dixie segment onto the shapefile with all other segments\n",
    "arcpy.management.Append(output_shp_dixie, output_shp, \"NO_TEST\")\n",
    "\n",
    "# Delete Dixie Segment\n",
    "arcpy.management.Delete(output_shp_dixie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the forecast area based on a lookup csv table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input feature layer (shapefile)\n",
    "inputShp = r'../intermediate/5_Merged_Segments.shp'\n",
    "outputShp = r'../intermediate/6_Merged_Segments.shp'\n",
    "csv_file = r'../data/cofips_subareaid_forecastarea.csv'\n",
    "\n",
    "arcpy.CopyFeatures_management(inputShp, outputShp)\n",
    "\n",
    "# Add the new field to the shapefile\n",
    "new_field_name = 'F_KEY'\n",
    "arcpy.AddField_management(outputShp, new_field_name, 'TEXT')\n",
    "\n",
    "# Calculate the values in the new field based on the expression\n",
    "with arcpy.da.UpdateCursor(outputShp, ['SUBAREAID', 'FIPS', new_field_name]) as cursor:\n",
    "    for row in cursor:\n",
    "        subarea_id = str(row[0])  # Convert to string if it's numeric\n",
    "        fips = str(row[1])  # Convert to string if it's numeric\n",
    "        # Delete the decimal and everything after it for the FIPS field\n",
    "        fips = fips.split('.')[0]\n",
    "        row[2] = \"{}_{}\".format(subarea_id, fips)\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# Perform the join between the shapefile and the CSV file\n",
    "join_field = 'F_KEY'\n",
    "arcpy.JoinField_management(outputShp, join_field, csv_file, join_field)        \n",
    "\n",
    "# Delete unwanted fields from the copied shapefile\n",
    "f_fields_to_keep = ['FID', 'Shape', 'SEGID', 'PLANAREA', 'DISTANCE','SUBAREAID', 'BMP','EMP', 'AADT2019', 'CO_FIPS', 'F_AREA']\n",
    "f_fields_to_delete = [field.name for field in arcpy.ListFields(outputShp) if field.name not in f_fields_to_keep]\n",
    "if f_fields_to_delete:\n",
    "    arcpy.management.DeleteField(outputShp, f_fields_to_delete)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Double Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should also do a 'pandas' check were we make sure every value from every field has data that that data isn't wrong\n",
    "inputShp = r'../intermediate/6_Merged_Segments.shp'\n",
    "df_merged = pd.DataFrame.spatial.from_featureclass(inputShp)\n",
    "df_merged = df_merged.drop(columns={'SHAPE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if there are any na values\n",
    "print(df_merged.isna().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>BMP</th>\n",
       "      <th>EMP</th>\n",
       "      <th>AADT2019</th>\n",
       "      <th>SUBAREAID</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CO_FIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8722.000000</td>\n",
       "      <td>8722.000000</td>\n",
       "      <td>8722.000000</td>\n",
       "      <td>8722.000000</td>\n",
       "      <td>8722.000000</td>\n",
       "      <td>8722.000000</td>\n",
       "      <td>8722.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4360.500000</td>\n",
       "      <td>26.850297</td>\n",
       "      <td>28.458421</td>\n",
       "      <td>9439.085187</td>\n",
       "      <td>1.146297</td>\n",
       "      <td>1.751495</td>\n",
       "      <td>34.481541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2517.968857</td>\n",
       "      <td>76.045354</td>\n",
       "      <td>76.238006</td>\n",
       "      <td>20157.555370</td>\n",
       "      <td>1.208336</td>\n",
       "      <td>3.567058</td>\n",
       "      <td>16.910631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025089</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2180.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371955</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4360.500000</td>\n",
       "      <td>1.529500</td>\n",
       "      <td>2.886500</td>\n",
       "      <td>2921.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.648495</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6540.750000</td>\n",
       "      <td>7.983500</td>\n",
       "      <td>10.598750</td>\n",
       "      <td>10961.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.379804</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8721.000000</td>\n",
       "      <td>499.375000</td>\n",
       "      <td>502.577000</td>\n",
       "      <td>287320.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>55.338206</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               FID          BMP  ...     DISTANCE      CO_FIPS\n",
       "count  8722.000000  8722.000000  ...  8722.000000  8722.000000\n",
       "mean   4360.500000    26.850297  ...     1.751495    34.481541\n",
       "std    2517.968857    76.045354  ...     3.567058    16.910631\n",
       "min       0.000000     0.000000  ...     0.025089     1.000000\n",
       "25%    2180.250000     0.000000  ...     0.371955    21.000000\n",
       "50%    4360.500000     1.529500  ...     0.648495    35.000000\n",
       "75%    6540.750000     7.983500  ...     1.379804    49.000000\n",
       "max    8721.000000   499.375000  ...    55.338206    57.000000\n",
       "\n",
       "[8 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some basic checks\n",
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, October 23, 2023 3:36:51 PM\",\"Succeeded at Monday, October 23, 2023 3:36:52 PM (Elapsed Time: 1.28 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'D:/GitHub/UDOT-Master-Segments/outputs\\\\Final_Segments.shp'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that our shapefile file looks good and is double checked, we can output it into the outputs folder\n",
    "inputShp = r'../intermediate/6_Merged_Segments.shp'\n",
    "outputShp = r'Final_Segments'\n",
    "\n",
    "arcpy.CopyFeatures_management(inputShp, outputShp)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
